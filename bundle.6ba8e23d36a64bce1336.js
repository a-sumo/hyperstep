(()=>{"use strict";var t,e={652:(t,e,n)=>{var r=n(477),a=n(217),i=n(304),o=n(365),s=n(659),c=n(792),d=n.n(c),l=n(614),u=n(998),m=n(324),f=n(916);class v extends r.jyz{constructor(t){super({uniforms:{matrix:{value:new r.yGw},zValue:{value:0},bvh:{value:new f.O}},vertexShader:"\n\n\t\t\t\tvarying vec2 vUv;\n\n\t\t\t\tvoid main() {\n\n\t\t\t\t\tvUv = uv;\n\t\t\t\t\tgl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 );\n\n\t\t\t\t}\n\n\t\t\t",fragmentShader:`\n\n\t\t\t\tprecision highp isampler2D;\n\t\t\t\tprecision highp usampler2D;\n\n\t\t\t\t${m.fZ}\n\t\t\t\t${m.TB}\n\t\t\t\t${m.Hb}\n\n\t\t\t\tvarying vec2 vUv;\n\n\t\t\t\tuniform BVH bvh;\n\t\t\t\tuniform float zValue;\n\t\t\t\tuniform mat4 matrix;\n\n\t\t\t\tvoid main() {\n\n\t\t\t\t\t// compute the point in space to check\n\t\t\t\t\tvec3 point = vec3( vUv, zValue );\n\t\t\t\t\tpoint -= vec3( 0.5 );\n\t\t\t\t\tpoint = ( matrix * vec4( point, 1.0 ) ).xyz;\n\n\t\t\t\t\t// retrieve the distance and other values\n\t\t\t\t\tuvec4 faceIndices;\n\t\t\t\t\tvec3 faceNormal;\n\t\t\t\t\tvec3 barycoord;\n\t\t\t\t\tfloat side;\n\t\t\t\t\tvec3 outPoint;\n\t\t\t\t\tfloat dist = bvhClosestPointToPoint( bvh, point.xyz, faceIndices, faceNormal, barycoord, side, outPoint );\n\n\t\t\t\t\t// if the triangle side is the back then it must be on the inside and the value negative\n\t\t\t\t\tgl_FragColor = vec4( side * dist, 0, 0, 0 );\n\n\t\t\t\t}\n\n\t\t\t`}),this.setValues(t)}}class p extends r.jyz{constructor(t){super({defines:{MAX_STEPS:500,SURFACE_EPSILON:.001},uniforms:{surface:{value:0},sdfTex:{value:null},normalStep:{value:new r.Pa4},projectionInverse:{value:new r.yGw},sdfTransformInverse:{value:new r.yGw}},vertexShader:"\n\n\t\t\t\tvarying vec2 vUv;\n\n\t\t\t\tvoid main() {\n\n\t\t\t\t\tvUv = uv;\n\t\t\t\t\tgl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 );\n\n\t\t\t\t}\n\n\t\t\t",fragmentShader:"\n\t\t\t\tprecision highp sampler3D;\n\n\t\t\t\tvarying vec2 vUv;\n\n\t\t\t\tuniform float surface;\n\t\t\t\tuniform sampler3D sdfTex;\n\t\t\t\tuniform vec3 normalStep;\n\t\t\t\tuniform mat4 projectionInverse;\n\t\t\t\tuniform mat4 sdfTransformInverse;\n\n\t\t\t\t#include <common>\n\n\t\t\t\t// distance to box bounds\n\t\t\t\tvec2 rayBoxDist( vec3 boundsMin, vec3 boundsMax, vec3 rayOrigin, vec3 rayDir ) {\n\n\t\t\t\t\tvec3 t0 = ( boundsMin - rayOrigin ) / rayDir;\n\t\t\t\t\tvec3 t1 = ( boundsMax - rayOrigin ) / rayDir;\n\t\t\t\t\tvec3 tmin = min( t0, t1 );\n\t\t\t\t\tvec3 tmax = max( t0, t1 );\n\n\t\t\t\t\tfloat distA = max( max( tmin.x, tmin.y ), tmin.z );\n\t\t\t\t\tfloat distB = min( tmax.x, min( tmax.y, tmax.z ) );\n\n\t\t\t\t\tfloat distToBox = max( 0.0, distA );\n\t\t\t\t\tfloat distInsideBox = max( 0.0, distB - distToBox );\n\t\t\t\t\treturn vec2( distToBox, distInsideBox );\n\n\t\t\t\t}\n\n\t\t\t\tvoid main() {\n\n\t\t\t\t\t// get the inverse of the sdf box transform\n\t\t\t\t\tmat4 sdfTransform = inverse( sdfTransformInverse );\n\n\t\t\t\t\t// convert the uv to clip space for ray transformation\n\t\t\t\t\tvec2 clipSpace = 2.0 * vUv - vec2( 1.0 );\n\n\t\t\t\t\t// get world ray direction\n\t\t\t\t\tvec3 rayOrigin = vec3( 0.0 );\n\t\t\t\t\tvec4 homogenousDirection = projectionInverse * vec4( clipSpace, - 1.0, 1.0 );\n\t\t\t\t\tvec3 rayDirection = normalize( homogenousDirection.xyz / homogenousDirection.w );\n\n\t\t\t\t\t// transform ray into local coordinates of sdf bounds\n\t\t\t\t\tvec3 sdfRayOrigin = ( sdfTransformInverse * vec4( rayOrigin, 1.0 ) ).xyz;\n\t\t\t\t\tvec3 sdfRayDirection = normalize( ( sdfTransformInverse * vec4( rayDirection, 0.0 ) ).xyz );\n\n\t\t\t\t\t// find whether our ray hits the box bounds in the local box space\n\t\t\t\t\tvec2 boxIntersectionInfo = rayBoxDist( vec3( - 0.5 ), vec3( 0.5 ), sdfRayOrigin, sdfRayDirection );\n\t\t\t\t\tfloat distToBox = boxIntersectionInfo.x;\n\t\t\t\t\tfloat distInsideBox = boxIntersectionInfo.y;\n\t\t\t\t\tbool intersectsBox = distInsideBox > 0.0;\n\n\t\t\t\t\tgl_FragColor = vec4( 0.0 );\n\t\t\t\t\tif ( intersectsBox ) {\n\n\t\t\t\t\t\t// find the surface point in world space\n\t\t\t\t\t\tbool intersectsSurface = false;\n\t\t\t\t\t\tvec4 localPoint = vec4( sdfRayOrigin + sdfRayDirection * ( distToBox + 1e-5 ), 1.0 );\n\t\t\t\t\t\tvec4 point = sdfTransform * localPoint;\n\n\t\t\t\t\t\t// ray march\n\t\t\t\t\t\tfor ( int i = 0; i < MAX_STEPS; i ++ ) {\n\n\t\t\t\t\t\t\t// sdf box extends from - 0.5 to 0.5\n\t\t\t\t\t\t\t// transform into the local bounds space [ 0, 1 ] and check if we're inside the bounds\n\t\t\t\t\t\t\tvec3 uv = ( sdfTransformInverse * point ).xyz + vec3( 0.5 );\n\t\t\t\t\t\t\tif ( uv.x < 0.0 || uv.x > 1.0 || uv.y < 0.0 || uv.y > 1.0 || uv.z < 0.0 || uv.z > 1.0 ) {\n\n\t\t\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t// get the distance to surface and exit the loop if we're close to the surface\n\t\t\t\t\t\t\tfloat distanceToSurface = texture2D( sdfTex, uv ).r - surface;\n\t\t\t\t\t\t\tif ( distanceToSurface < SURFACE_EPSILON ) {\n\n\t\t\t\t\t\t\t\tintersectsSurface = true;\n\t\t\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t// step the ray\n\t\t\t\t\t\t\tpoint.xyz += rayDirection * abs( distanceToSurface );\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// find the surface normal\n\t\t\t\t\t\tif ( intersectsSurface ) {\n\n\t\t\t\t\t\t\t// compute the surface normal\n\t\t\t\t\t\t\tvec3 uv = ( sdfTransformInverse * point ).xyz + vec3( 0.5 );\n\t\t\t\t\t\t\tfloat dx = texture( sdfTex, uv + vec3( normalStep.x, 0.0, 0.0 ) ).r - texture( sdfTex, uv - vec3( normalStep.x, 0.0, 0.0 ) ).r;\n\t\t\t\t\t\t\tfloat dy = texture( sdfTex, uv + vec3( 0.0, normalStep.y, 0.0 ) ).r - texture( sdfTex, uv - vec3( 0.0, normalStep.y, 0.0 ) ).r;\n\t\t\t\t\t\t\tfloat dz = texture( sdfTex, uv + vec3( 0.0, 0.0, normalStep.z ) ).r - texture( sdfTex, uv - vec3( 0.0, 0.0, normalStep.z ) ).r;\n\t\t\t\t\t\t\tvec3 normal = normalize( vec3( dx, dy, dz ) );\n\n\t\t\t\t\t\t\t// compute some basic lighting effects\n\t\t\t\t\t\t\tvec3 lightDirection = normalize( vec3( 1.0 ) );\n\t\t\t\t\t\t\tfloat lightIntensity =\n\t\t\t\t\t\t\t\tsaturate( dot( normal, lightDirection ) ) +\n\t\t\t\t\t\t\t\tsaturate( dot( normal, - lightDirection ) ) * 0.05 +\n\t\t\t\t\t\t\t\t0.1;\n\t\t\t\t\t\t\tgl_FragColor.rgb = vec3( lightIntensity );\n\t\t\t\t\t\t\tgl_FragColor.a = 1.0;\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\n\t\t\t\t\t#include <encodings_fragment>\n\n\t\t\t\t}\n\t\t\t"}),this.setValues(t)}}class h extends r.jyz{constructor(t){super({defines:{MAX_STEPS:100,SURFACE_EPSILON:.001},uniforms:{surface:{value:0},sdfTex:{value:null},dataTex:{value:null},normalStep:{value:new r.Pa4},projectionInverse:{value:new r.yGw},sdfTransformInverse:{value:new r.yGw}},vertexShader:"\n\t\t\t\tvarying vec2 vUv;\n\t\t\t\tvoid main() {\n\t\t\t\t\tvUv = uv;\n\t\t\t\t\tgl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 );\n\t\t\t\t}\n\t\t\t",fragmentShader:"\n\t\t\t\tprecision highp sampler3D;\n\t\t\t\tvarying vec2 vUv;\n\t\t\t\tuniform float surface;\n\t\t\t\tuniform sampler3D sdfTex;\n                uniform sampler2D dataTex;\n\t\t\t\tuniform vec3 normalStep;\n\t\t\t\tuniform mat4 projectionInverse;\n\t\t\t\tuniform mat4 sdfTransformInverse;\n\t\t\t\t#include <common>\n\t\t\t\t// distance to box bounds\n\t\t\t\tvec2 rayBoxDist( vec3 boundsMin, vec3 boundsMax, vec3 rayOrigin, vec3 rayDir ) {\n\t\t\t\t\tvec3 t0 = ( boundsMin - rayOrigin ) / rayDir;\n\t\t\t\t\tvec3 t1 = ( boundsMax - rayOrigin ) / rayDir;\n\t\t\t\t\tvec3 tmin = min( t0, t1 );\n\t\t\t\t\tvec3 tmax = max( t0, t1 );\n\t\t\t\t\tfloat distA = max( max( tmin.x, tmin.y ), tmin.z );\n\t\t\t\t\tfloat distB = min( tmax.x, min( tmax.y, tmax.z ) );\n\t\t\t\t\tfloat distToBox = max( 0.0, distA );\n\t\t\t\t\tfloat distInsideBox = max( 0.0, distB - distToBox );\n\t\t\t\t\treturn vec2( distToBox, distInsideBox );\n\t\t\t\t}\n\t\t\t\tvoid main() {\n\t\t\t\t\t// get the inverse of the sdf box transform\n\t\t\t\t\tmat4 sdfTransform = inverse( sdfTransformInverse );\n\t\t\t\t\t// convert the uv to clip space for ray transformation\n\t\t\t\t\tvec2 clipSpace = 2.0 * vUv - vec2( 1.0 );\n\t\t\t\t\t// get world ray direction\n\t\t\t\t\tvec3 rayOrigin = vec3( 0.0 );\n\t\t\t\t\tvec4 homogenousDirection = projectionInverse * vec4( clipSpace, - 1.0, 1.0 );\n\t\t\t\t\tvec3 rayDirection = normalize( homogenousDirection.xyz / homogenousDirection.w );\n\t\t\t\t\t// transform ray into local coordinates of sdf bounds\n\t\t\t\t\tvec3 sdfRayOrigin = ( sdfTransformInverse * vec4( rayOrigin, 1.0 ) ).xyz;\n\t\t\t\t\tvec3 sdfRayDirection = normalize( ( sdfTransformInverse * vec4( rayDirection, 0.0 ) ).xyz );\n\t\t\t\t\t// find whether our ray hits the box bounds in the local box space\n\t\t\t\t\tvec2 boxIntersectionInfo = rayBoxDist( vec3( - 0.5 ), vec3( 0.5 ), sdfRayOrigin, sdfRayDirection );\n\t\t\t\t\tfloat distToBox = boxIntersectionInfo.x;\n\t\t\t\t\tfloat distInsideBox = boxIntersectionInfo.y;\n\t\t\t\t\tbool intersectsBox = distInsideBox > 0.0;\n\t\t\t\t\tgl_FragColor = vec4( 0.0 );\n\t\t\t\t\tif ( intersectsBox ) {\n\t\t\t\t\t\t// find the surface point in world space\n\t\t\t\t\t\tbool intersectsSurface = false;\n\t\t\t\t\t\tvec4 localPoint = vec4( sdfRayOrigin + sdfRayDirection * ( distToBox + 1e-5 ), 1.0 );\n\t\t\t\t\t\tvec4 point = sdfTransform * localPoint;\n\t\t\t\t\t\tint step = 0;\n\t\t\t\t\t\t// ray march\n\t\t\t\t\t\tfor ( int i = 0; i < MAX_STEPS; i ++ ) {\n\t\t\t\t\t\t\t// sdf box extends from - 0.5 to 0.5\n\t\t\t\t\t\t\t// transform into the local bounds space [ 0, 1 ] and check if we're inside the bounds\n\t\t\t\t\t\t\tvec3 uv = ( sdfTransformInverse * point ).xyz + vec3( 0.5 );\n\t\t\t\t\t\t\tif ( uv.x < 0.0 || uv.x > 1.0 || uv.y < 0.0 || uv.y > 1.0 || uv.z < 0.0 || uv.z > 1.0 ) {\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t// // get the distance to surface and exit the loop if we're close to the surface\n\t\t\t\t\t\t\t// float distanceToSurface = texture2D( sdfTex, uv ).r - surface;\n\t\t\t\t\t\t\t// if ( distanceToSurface < SURFACE_EPSILON ) {\n\t\t\t\t\t\t\t// \tintersectsSurface = true;\n\t\t\t\t\t\t\t// \tbreak;\n\t\t\t\t\t\t\t// }\n                            // get the distance value\n\t\t\t\t\t\t\tfloat distance = abs(texture2D( sdfTex, uv - 0.5).r);\n\t\t\t\t\t\t\tdistance = distance * 0.1; \n\t\t\t\t\t\t\tdistance = clamp(length(uv-vec3(0.5)), 0.0, 1.0);\n\t\t\t\t\t\t\t// sample data texture along distance value\n                            vec2 uv2 = vec2(0., distance);\n                            float dataSample = texture(dataTex, uv2).r;\n\t\t\t\t\t\t\tvec4 baseColor = vec4(pow(dataSample,10.0) * distance,\n\t\t\t\t\t\t\tpow(dataSample, 2.0),\n\t\t\t\t\t\t\tpow(dataSample, 0.0) * distance, dataSample) ;\n\t\t\t\t\t\n\t\t\t\t\t\t\t// vec4 baseColor = vec4(distance,0., 0., 0.4);\n\t\t\t\t\t\t\t// baseColor.rgb = uv;\n\t\t\t\t\t\t\t// baseColor.w = 1.0;\n                            // Opacity correction\n\t\t\t\t\t\t\tbaseColor.w = 1.0 - pow(1.0 - baseColor.w, 0.01);\n                            // Alpha-blending\n                            gl_FragColor.rbg += (1.0 -  gl_FragColor.a) * baseColor.a * baseColor.xyz;\n\t\t\t\t\t\t\tgl_FragColor.a += (1.0 - gl_FragColor.a) * baseColor.w;\n                            // exit the loop if the accumulated alpha is close to 1\n                            // if (gl_FragColor.a > 0.9) {\n                            //   break;\n                            // }\n\t\t\t\t\t\t\t// step the ray\n\t\t\t\t\t\t\tpoint.xyz += rayDirection * 0.01;\n\t\t\t\t\t\t}\n\t\n\t\t\t\t\t\t// // find the surface normal\n\t\t\t\t\t\t// if ( intersectsSurface ) {\n\t\t\t\t\t\t// \t// compute the surface normal\n\t\t\t\t\t\t// \tvec3 uv = ( sdfTransformInverse * point ).xyz + vec3( 0.5 );\n\t\t\t\t\t\t// \tfloat dx = texture( sdfTex, uv + vec3( normalStep.x, 0.0, 0.0 ) ).r - texture( sdfTex, uv - vec3( normalStep.x, 0.0, 0.0 ) ).r;\n\t\t\t\t\t\t// \tfloat dy = texture( sdfTex, uv + vec3( 0.0, normalStep.y, 0.0 ) ).r - texture( sdfTex, uv - vec3( 0.0, normalStep.y, 0.0 ) ).r;\n\t\t\t\t\t\t// \tfloat dz = texture( sdfTex, uv + vec3( 0.0, 0.0, normalStep.z ) ).r - texture( sdfTex, uv - vec3( 0.0, 0.0, normalStep.z ) ).r;\n\t\t\t\t\t\t// \tvec3 normal = normalize( vec3( dx, dy, dz ) );\n\t\t\t\t\t\t// \t// compute some basic lighting effects\n\t\t\t\t\t\t// \tvec3 lightDirection = normalize( vec3( 1.0 ) );\n\t\t\t\t\t\t// \tfloat lightIntensity =\n\t\t\t\t\t\t// \t\tsaturate( dot( normal, lightDirection ) ) +\n\t\t\t\t\t\t// \t\tsaturate( dot( normal, - lightDirection ) ) * 0.05 +\n\t\t\t\t\t\t// \t\t0.1;\n\t\t\t\t\t\t// \tgl_FragColor.rgb = vec3( lightIntensity );\n\t\t\t\t\t\t// \tgl_FragColor.a = 1.0;\n\t\t\t\t\t\t// }\n\t\t\t\t\t}\n\t\t\t\t\t#include <encodings_fragment>\n\t\t\t\t}\n\t\t\t"}),this.setValues(t)}}var g=n(917);function x(t){const e=t.map((t=>fetch(t).then((t=>t.text()))));return Promise.all(e).then((t=>{t.unshift("var exports = {};");const e=t.join(""),n=new Blob([e],{type:"text/javascript"});return URL.createObjectURL(n)}))}const y=n.p+"3e3ec63d65dbac197668.mp3",w=n.p+"af94b875b527644acadf.mp3",b=n.p+"7b5db9c538fd2fd44406.mp3",T={gpuGeneration:!0,resolution:75,margin:.2,regenerate:()=>rt(),mode:"raycasting",surface:-.3,bufferSize:1024,hopSize:512,melNumBands:96,numFrames:1};let _,S,A,I,z,B,D,M,j,E,P,C,F,R,O,U,k,L,W,N,V,G,q,H=96,X={};X=n(490);const $=new r.yGw,Y=document.getElementById("loadFileInput"),J=document.getElementById("recordButton"),Z=document.getElementById("audioPlayer"),K={"audio-1":y,"audio-2":w,"audio-3":b},Q=window.URL||window.webkitURL,tt=document.getElementById("button-group");let et=[];function nt(){I&&I.destroy(),I=new s.XS;const t=I.addFolder("generation");t.add(T,"gpuGeneration"),t.add(T,"resolution",10,200,1),t.add(T,"margin",0,1),t.add(T,"regenerate");const e=I.addFolder("display");e.add(T,"mode",["geometry","raymarching","raycasting"]).onChange((()=>{nt()})),"raymarching"===T.mode&&e.add(T,"surface",-.2,.5),"raycasting"===T.mode&&e.add(T,"surface",-.5,.5)}function rt(){const t=T.resolution,e=new r.yGw,n=new r.Pa4,a=new r._fP,i=new r.Pa4;U.boundingBox.getCenter(n),i.subVectors(U.boundingBox.max,U.boundingBox.min),i.x+=2*T.margin,i.y+=2*T.margin,i.z+=2*T.margin,e.compose(n,a,i),$.copy(e).invert(),B.box.copy(U.boundingBox),B.box.min.x-=T.margin,B.box.min.y-=T.margin,B.box.min.z-=T.margin,B.box.max.x+=T.margin,B.box.max.y+=T.margin,B.box.max.z+=T.margin,k&&k.dispose();const o=1/t,s=.5*o,c=window.performance.now();if(T.gpuGeneration){k=new r.Ywn(t,t,t),k.texture.format=r.hEm,k.texture.type=r.VzW,k.texture.minFilter=r.wem,k.texture.magFilter=r.wem,k.needsUpdate=!0,N.material.uniforms.bvh.value.updateFrom(O),N.material.uniforms.matrix.value.copy(e);for(let e=0;e<t;e++)N.material.uniforms.zValue.value=e*o+s,_.setRenderTarget(k,e),N.render(_);_.readRenderTargetPixels(k,0,0,1,1,new Float32Array(4)),_.setRenderTarget(null)}else{k=new r.JUT(new Float32Array(t**3),t,t,t),k.format=r.hEm,k.type=r.VzW,k.minFilter=r.wem,k.magFilter=r.wem;const n=U.attributes.position,a=U.index,i=new r.Pa4,c=new r.Pa4,d=new r.Pa4,l=new r.CJI,u={};for(let r=0;r<t;r++)for(let m=0;m<t;m++)for(let f=0;f<t;f++){i.set(s+r*o-.5,s+m*o-.5,s+f*o-.5).applyMatrix4(e);const v=r+m*t+f*t*t,p=O.closestPointToPoint(i,u).distance,h=u.faceIndex,g=a.getX(3*h+0),x=a.getX(3*h+1),y=a.getX(3*h+2);l.setFromAttributeAndIndices(n,g,x,y),l.getNormal(c),d.subVectors(u.point,i),k.image.data[v]=c.dot(d)>0?-p:p}}const d=window.performance.now()-c;R.innerText=`${d.toFixed(2)}ms`,nt()}function at(){J.classList.contains("recording")?(J.classList.remove("recording"),J.innerHTML="Record",J.classList.remove("bg-emerald-200"),J.disabled=!1,M.getAudioTracks().forEach((function(t){t.stop(),M.removeTrack(t)})),D.close().then((function(){P.disconnect(),F.disconnect(),C.disconnect(),P=void 0,F=void 0,C=void 0,console.log("Stopped recording ...")}))):(J.classList.add("recording"),J.innerHTML="Stop",J.classList.add("bg-emerald-200"),function(){if(!navigator.mediaDevices.getUserMedia)throw"Could not access microphone - getUserMedia not available";console.log("Initializing audio..."),navigator.mediaDevices.getUserMedia({audio:!0,video:!1}).then(ot).catch((function(t){throw"Could not access microphone - "+t}))}())}function it(){Z.paused?D.close().then((function(){j.disconnect(),F.disconnect(),j=void 0,F=void 0})):("closed"==D.state?D=new AudioContext:"suspended"==D.state&&D.resume(),j=D.createMediaElementSource(Z),C=D.createGain(),C.gain.setValueAtTime(0,D.currentTime),x(["https://cdn.jsdelivr.net/npm/essentia.js@0.1.3/dist/essentia-wasm.umd.js","https://cdn.jsdelivr.net/npm/essentia.js@0.1.3/dist/essentia.js-extractor.umd.js","https://raw.githack.com/MTG/essentia.js/master/examples/demos/melspectrogram-rt/melspectrogram-processor.js","https://unpkg.com/ringbuf.js@0.1.0/dist/index.js"]).then((t=>{D.audioWorklet.addModule(t).then(ct).catch((function(t){console.log(`There was a problem loading the AudioWorklet module code: \n ${t}`)}))})).catch((t=>{console.log(`There was a problem retrieving the AudioWorklet module code: \n ${t}`)})))}function ot(t){if(M=t,!M.active)throw"Mic stream not active";"closed"==D.state?D=new AudioContext:"suspended"==D.state&&D.resume(),P=D.createMediaStreamSource(M),C=D.createGain(),C.gain.setValueAtTime(0,D.currentTime),x(["https://cdn.jsdelivr.net/npm/essentia.js@0.1.3/dist/essentia-wasm.umd.js","https://cdn.jsdelivr.net/npm/essentia.js@0.1.3/dist/essentia.js-extractor.umd.js","https://raw.githack.com/MTG/essentia.js/master/examples/demos/melspectrogram-rt/melspectrogram-processor.js","https://unpkg.com/ringbuf.js@0.1.0/dist/index.js"]).then((t=>{D.audioWorklet.addModule(t).then(st).catch((function(t){console.log(`There was a problem loading the AudioWorklet module code: \n ${t}`)}))})).catch((t=>{console.log(`There was a problem retrieving the AudioWorklet module code: \n ${t}`)}))}function st(){let t=X.RingBuffer.getStorageForCapacity(4032,Float32Array),e=new X.RingBuffer(t,Float32Array);E=new X.AudioReader(e),F=new AudioWorkletNode(D,"melspectrogram-processor",{processorOptions:{bufferSize:1024,hopSize:512,melNumBands:H,sampleRate:D.sampleRate}});try{F.port.postMessage({sab:t})}catch(t){return alert("No SharedArrayBuffer transfer support, try another browser."),void(J.disabled=!0)}P.connect(F),F.connect(C),C.connect(D.destination)}function ct(){let t=X.RingBuffer.getStorageForCapacity(1728,Float32Array),e=new X.RingBuffer(t,Float32Array);E=new X.AudioReader(e),F=new AudioWorkletNode(D,"melspectrogram-processor",{processorOptions:{bufferSize:1024,hopSize:512,melNumBands:H,sampleRate:D.sampleRate}});try{F.port.postMessage({sab:t})}catch(t){return void alert("No SharedArrayBuffer transfer support, try another browser.")}j.connect(D.destination),j.connect(F),F.connect(C),C.connect(D.destination)}!function(){R=document.getElementById("output"),_=new r.CP7({antialias:!0}),_.setPixelRatio(window.devicePixelRatio),_.setSize(window.innerWidth,window.innerHeight),_.setClearColor(0,0),_.outputEncoding=r.knz,document.body.appendChild(_.domElement),A=new r.xsS;const t=new r.Ox3(16777215,1);t.position.set(1,1,1),A.add(t),A.add(new r.Mig(16777215,.2)),S=new r.cPb(75,window.innerWidth/window.innerHeight,.1,50),S.position.set(1,1,2),S.far=100,S.updateProjectionMatrix(),B=new r.GQ(new r.ZzF),A.add(B);const e=new r.y8_(3);A.add(e),new o.z(S,_.domElement),z=new(d()),N=new i.T(new v),V=new i.T(new p),G=new i.T(new h),q=new l.a,(new a.E).setMeshoptDecoder(g.z).loadAsync("https://raw.githubusercontent.com/gkjohnson/3d-demo-data/main/models/stanford-bunny/bunny.glb").then((t=>{t.scene.updateMatrixWorld(!0);const e=new u.H(t.scene);return e.attributes=["position","normal"],e.useGroups=!1,U=e.generate().center(),q.generate(U,{maxLeafTris:1})})).then((t=>{O=t,W=new r.Kj0(U,new r.Wid),A.add(W),rt()})),nt();let n=navigator;void 0===n.mediaDevices&&(n.mediaDevices={});try{AudioContext=window.AudioContext||window.webkitAudioContext,D=new AudioContext}catch(t){throw"Could not instantiate AudioContext: "+t.message}Z.src=K["audio-1"],Z.load(),function(t,e){L=new r.IEO(new Uint8Array(384),1,96),L.format=r.wk1,L.minFilter=r.wem,L.magFilter=r.wem,L.unpackAlignment=1,L.needsUpdate=!0;let n=0;for(let t=0;t<96;t++)for(let t=0;t<1;t++)L[n+0]=255,L[n+1]=0,L[n+2]=0,L[n+3]=255,n+=4}(),window.addEventListener("resize",(function(){S.aspect=window.innerWidth/window.innerHeight,S.updateProjectionMatrix(),_.setSize(window.innerWidth,window.innerHeight)}),!1),J.addEventListener("click",at),Z.addEventListener("play",it),Z.addEventListener("pause",it),Y.addEventListener("change",(()=>{var t;t=Y,Z.src=Q.createObjectURL(t.files[0]),Z.load()})),tt.addEventListener("click",(t=>{"BUTTON"===t.target.nodeName&&(Z.src=K[t.target.id],Z.load())}))}(),function t(){if(z.update(),requestAnimationFrame(t),k)if("geometry"===T.mode)_.render(A,S);else if("raymarching"===T.mode){let t;S.updateMatrixWorld(),W.updateMatrixWorld(),t=k.isData3DTexture?k:k.texture;const{width:e,depth:n,height:r}=t.image;V.material.uniforms.sdfTex.value=t,console.log,V.material.uniforms.normalStep.value.set(1/e,1/r,1/n),V.material.uniforms.surface.value=T.surface,V.material.uniforms.projectionInverse.value.copy(S.projectionMatrixInverse),V.material.uniforms.sdfTransformInverse.value.copy(W.matrixWorld).invert().premultiply($).multiply(S.matrixWorld),V.render(_)}else if("raycasting"===T.mode){let t=new Float32Array(H);void 0!==E&&E.available_read()>=H&&0!==E.dequeue(t)&&(et=t.map((t=>Math.round(35.5*t))));const e=1,n=H;L=new r.IEO(new Uint8Array(e*n*4),e,n),L.format=r.wk1,L.minFilter=r.TyD,L.magFilter=r.TyD,L.unpackAlignment=1,L.needsUpdate=!0,L.image.data;let a,i=0;for(let t=0;t<n;t++)for(let n=0;n<e;n++)L.image.data[i]=n<e-1?L.image.data[i+4]:et[t],L.image.data[i+1]=0,L.image.data[i+2]=0,L.image.data[i+3]=1,i+=4;S.updateMatrixWorld(),W.updateMatrixWorld(),a=k.isData3DTexture?k:k.texture;const{width:o,depth:s,height:c}=a.image;G.material.uniforms.sdfTex.value=a.texture,G.material.uniforms.dataTex.value=L,G.material.uniforms.normalStep.value.set(1/o,1/c,1/s),G.material.uniforms.surface.value=T.surface,G.material.uniforms.projectionInverse.value.copy(S.projectionMatrixInverse),G.material.uniforms.sdfTransformInverse.value.copy(W.matrixWorld).invert().premultiply($).multiply(S.matrixWorld),G.render(_)}}()},490:(t,e)=>{Object.defineProperty(e,"__esModule",{value:!0}),e.AudioReader=class{constructor(t){if("Float32Array"!=t.type())throw"This class requires a ring buffer of Float32Array";this.ringbuf=t}dequeue(t){return this.ringbuf.empty()?0:this.ringbuf.pop(t)}available_read(){return this.ringbuf.available_read()}},e.AudioWriter=class{constructor(t){if("Float32Array"!=t.type())throw"This class requires a ring buffer of Float32Array";this.ringbuf=t}enqueue(t){return this.ringbuf.push(t)}available_write(){return this.ringbuf.available_write()}},e.ParameterReader=class{constructor(t){this.ringbuf=t,this.mem=new ArrayBuffer(5),this.array=new Uint8Array(this.mem),this.view=new DataView(this.mem)}dequeue_change(t){return!this.ringbuf.empty()&&(this.ringbuf.pop(this.array),t.index=this.view.getUint8(0),t.value=this.view.getFloat32(1),!0)}},e.ParameterWriter=class{constructor(t){if("Uint8Array"!=t.type())throw"This class requires a ring buffer of Uint8Array";this.ringbuf=t,this.mem=new ArrayBuffer(5),this.array=new Uint8Array(this.mem),this.view=new DataView(this.mem)}enqueue_change(t,e){return this.view.setUint8(0,t),this.view.setFloat32(1,e),!(this.ringbuf.available_write()<5)&&5==this.ringbuf.push(this.array)}},e.RingBuffer=class{static getStorageForCapacity(t,e){if(!e.BYTES_PER_ELEMENT)throw"Pass in a ArrayBuffer subclass";var n=8+(t+1)*e.BYTES_PER_ELEMENT;return new SharedArrayBuffer(n)}constructor(t,e){if(!ArrayBuffer.__proto__.isPrototypeOf(e)&&void 0!==e.BYTES_PER_ELEMENT)throw"Pass a concrete typed array class as second argument";this._type=e,this.capacity=(t.byteLength-8)/e.BYTES_PER_ELEMENT,this.buf=t,this.write_ptr=new Uint32Array(this.buf,0,1),this.read_ptr=new Uint32Array(this.buf,4,1),this.storage=new e(this.buf,8,this.capacity)}type(){return this._type.name}push(t){var e=Atomics.load(this.read_ptr,0),n=Atomics.load(this.write_ptr,0);if((n+1)%this._storage_capacity()==e)return 0;let r=Math.min(this._available_write(e,n),t.length),a=Math.min(this._storage_capacity()-n,r),i=r-a;return this._copy(t,0,this.storage,n,a),this._copy(t,a,this.storage,0,i),Atomics.store(this.write_ptr,0,(n+r)%this._storage_capacity()),r}pop(t){var e=Atomics.load(this.read_ptr,0),n=Atomics.load(this.write_ptr,0);if(n==e)return 0;let r=Math.min(this._available_read(e,n),t.length),a=Math.min(this._storage_capacity()-e,t.length),i=r-a;return this._copy(this.storage,e,t,0,a),this._copy(this.storage,0,t,a,i),Atomics.store(this.read_ptr,0,(e+r)%this._storage_capacity()),r}empty(){var t=Atomics.load(this.read_ptr,0);return Atomics.load(this.write_ptr,0)==t}full(){var t=Atomics.load(this.read_ptr,0);return(Atomics.load(this.write_ptr,0)+1)%this.capacity!=t}capacity(){return this.capacity-1}available_read(){var t=Atomics.load(this.read_ptr,0),e=Atomics.load(this.write_ptr,0);return this._available_read(t,e)}available_write(){var t=Atomics.load(this.read_ptr,0),e=Atomics.load(this.write_ptr,0);return this._available_write(t,e)}_available_read(t,e){return e>t?e-t:e+this._storage_capacity()-t}_available_write(t,e){let n=t-e-1;return e>=t&&(n+=this._storage_capacity()),n}_storage_capacity(){return this.capacity}_copy(t,e,n,r,a){for(var i=0;i<a;i++)n[r+i]=t[e+i]}},e.deinterleave=function(t,e){var n=t.length/256;if(e.length!=n)throw"not enough space in output arrays";for(var r=0;r<channelCount;r++){let i=e[r],o=r;for(var a=0;a<128;++a)i[a]=t[o],o+=n}},e.interleave=function(t,e){if(128*t.length!=e.length)throw"input and output of incompatible sizes";for(var n=0,r=0;r<128;r++)for(;j<e.length;j++)e[n]=t[0][r],n++}}},n={};function r(t){var a=n[t];if(void 0!==a)return a.exports;var i=n[t]={exports:{}};return e[t].call(i.exports,i,i.exports,r),i.exports}r.m=e,t=[],r.O=(e,n,a,i)=>{if(!n){var o=1/0;for(l=0;l<t.length;l++){for(var[n,a,i]=t[l],s=!0,c=0;c<n.length;c++)(!1&i||o>=i)&&Object.keys(r.O).every((t=>r.O[t](n[c])))?n.splice(c--,1):(s=!1,i<o&&(o=i));if(s){t.splice(l--,1);var d=a();void 0!==d&&(e=d)}}return e}i=i||0;for(var l=t.length;l>0&&t[l-1][2]>i;l--)t[l]=t[l-1];t[l]=[n,a,i]},r.n=t=>{var e=t&&t.__esModule?()=>t.default:()=>t;return r.d(e,{a:e}),e},r.d=(t,e)=>{for(var n in e)r.o(e,n)&&!r.o(t,n)&&Object.defineProperty(t,n,{enumerable:!0,get:e[n]})},r.u=t=>"bundle.6e28ccc78870e32f327a.js",r.o=(t,e)=>Object.prototype.hasOwnProperty.call(t,e),r.p="/hyperstep/",(()=>{r.b=document.baseURI||self.location.href;var t={271:0};r.O.j=e=>0===t[e];var e=(e,n)=>{var a,i,[o,s,c]=n,d=0;if(o.some((e=>0!==t[e]))){for(a in s)r.o(s,a)&&(r.m[a]=s[a]);if(c)var l=c(r)}for(e&&e(n);d<o.length;d++)i=o[d],r.o(t,i)&&t[i]&&t[i][0](),t[i]=0;return r.O(l)},n=self.webpackChunk=self.webpackChunk||[];n.forEach(e.bind(null,0)),n.push=e.bind(null,n.push.bind(n))})();var a=r.O(void 0,[365,996,659,732],(()=>r(652)));a=r.O(a)})();
//# sourceMappingURL=bundle.6ba8e23d36a64bce1336.js.map